name: Testing tools against a file

on:
  workflow_dispatch: # Allows you to run this workflow manually

permissions:
  contents: write # We only need to read the repository contents

jobs:
  prepare-chunks:
    name: Prepare Chunks and Build Matrix
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.build_matrix.outputs.matrix }}
      chunk_count: ${{ steps.build_matrix.outputs.chunk_count }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Create Chunks and Build Matrix
        id: build_matrix
        shell: bash
        run: |
          # Exit on any error, print all commands to the log for debugging
          set -ex

          # --- 1. CONFIGURATION AND SETUP ---
          INPUT_FILE="target.txt"
          CHUNK_SIZE=100
          CHUNK_DIR="chunks"

          if [ ! -f "$INPUT_FILE" ]; then
            echo "::error::Input file '$INPUT_FILE' not found in the repository root."
            exit 1
          fi

          mkdir -p "$CHUNK_DIR"
          echo "-> Splitting '$INPUT_FILE' into chunks of $CHUNK_SIZE lines..."
          split -l "$CHUNK_SIZE" -a 3 --numeric-suffixes=1 "$INPUT_FILE" "$CHUNK_DIR/chunk_"
          
          echo "-> Chunk files created in '$CHUNK_DIR' directory:"
          ls -l "$CHUNK_DIR"

          # --- 2. COUNT THE CHUNKS ---
          # A simple and reliable way to count the files.
          CHUNK_COUNT=$(find "$CHUNK_DIR" -type f -name 'chunk_*' | wc -l)

          if [ "$CHUNK_COUNT" -eq 0 ]; then
            echo "::warning::Splitting produced 0 chunk files. No work to do."
            echo "matrix=[]" >> "$GITHUB_OUTPUT"
            echo "chunk_count=0" >> "$GITHUB_OUTPUT"
            exit 0 # Exit successfully as there is no work
          fi
          echo "-> Found $CHUNK_COUNT chunk files to process."

          # --- 3. BUILD THE MATRIX (SIMPLIFIED & DIRECT METHOD) ---
          # This is the most robust way: list files, pipe to jq to build the JSON.
          # The jq command transforms each line of input into a JSON object.
          # The -R (raw input) and -s (slurp) flags read the entire input into a single array.
          JSON_MATRIX=$(find "$CHUNK_DIR" -type f -name 'chunk_*' | jq -R -s -c 'split("\n") | map(select(length > 0)) | map({chunk_file: .})')

          # --- 4. VERIFY AND OUTPUT ---
          echo "-> Verifying that the generated matrix is valid JSON..."
          echo "$JSON_MATRIX" | jq .
          
          echo "-> Matrix verification successful."
          echo "Final Matrix: $JSON_MATRIX"
          
          echo "matrix=$JSON_MATRIX" >> "$GITHUB_OUTPUT"
          echo "chunk_count=$CHUNK_COUNT" >> "$GITHUB_OUTPUT"



      - name: Upload Chunks as Artifact
        uses: actions/upload-artifact@v4
        with:
          name: output-chunks
          path: chunks/
          retention-days: 1

  run-tools-in-parallel:
    needs: prepare-chunks
    if: ${{ needs.prepare-chunks.outputs.chunk_count > 0 }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        # This creates a parallel job for each file path in the matrix output from the previous job
        chunk_file: ${{ fromJson(needs.prepare-chunks.outputs.matrix) }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          # Fetch full Git history so previous commits are available for comparison
          fetch-depth: 0   
          
      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.23'

      - name: Cache Go modules & binaries
        uses: actions/cache@v3
        with:
          path: |
            $HOME/go/pkg/mod
            ~/.cache/go-build
            $HOME/go/bin
          key: ${{ runner.os }}-go-cache-${{ github.ref_name }}
          restore-keys: |
            ${{ runner.os }}-go-cache-

      - name: Install Tools
        run: |
          # Installing httpx
          if ! command -v httpx >/dev/null; then
            echo "Installing httpxâ€¦"
            go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest
          else
            echo "httpx already in cache"
          fi    

      - name: Download Chunks Artifact
        uses: actions/download-artifact@v4
        with:
          name: output-chunks
          path: chunks/

      - name: Debug Matrix Context
        run: |
          echo "Matrix context for this job:"
          echo "${{ toJson(matrix) }}"

      # --- CORRECTED RUN STEP ---
      - name: Run tools on Chunks
        id: run_tool
        # This 'env' block safely passes the chunk_file path to an environment variable.
        env:
          CHUNK_PATH: ${{ matrix.chunk_file }}
        run: |
          # Exit on error, print commands
          set -ex

          # Verify that the environment variable was passed correctly
          if [[ -z "$CHUNK_PATH" ]]; then
            echo "::error:: CHUNK_PATH environment variable was not set correctly!"
            
          fi

          # Verify the chunk file actually exists after artifact download
          if [ ! -f "$CHUNK_PATH" ]; then
            echo "::error:: Chunk file '$CHUNK_PATH' does not exist after download."
            ls -R . # List all downloaded files for debugging
            
          fi

          # Now, use the reliable environment variable instead of direct context.
          CHUNK_BASENAME=$(basename "$CHUNK_PATH")
          OUTPUT_DIR="results"
          OUTPUT_FILE="$OUTPUT_DIR/result_$CHUNK_BASENAME"
          mkdir -p "$OUTPUT_DIR"

          echo "Running httpx on file: $CHUNK_PATH"
         
          httpx  -l "$CHUNK_PATH"" -t 100 -o "$OUTPUT_FILE" -rl 100 -random-agent -delay 200ms -silent 
          
          
          # ------------------------------------

          echo "output_file=$OUTPUT_FILE" >> $GITHUB_OUTPUT

      - name: Upload Individual Result Artifact
        uses: actions/upload-artifact@v4
        with:
          name: result-${{ matrix.chunk_file }}
          path: ${{ steps.run_tool.outputs.output_file }}
          retention-days: 1 

  aggregate-results:
    needs: run-tools-in-parallel
    if: always() # This ensures the aggregation job runs even if some nuclei jobs fail
    runs-on: ubuntu-latest
    steps:
      - name: Create Temporary Directory for Results
        run: mkdir -p temp-results

      - name: Download All Result Artifacts
        uses: actions/download-artifact@v4
        with:
          path: temp-results/
          pattern: result-chunks/chunk_*.txt
          merge-multiple: true

      - name: Aggregate All Results into a Single File
        id: aggregate
        run: |
          echo "Aggregating all results..."
          # Combine all downloaded result files into one.
          # The `sort -u` command will also remove any duplicate findings.
          cat temp-results/* | sort -u > nuclei-final-results.txt
          echo "Final aggregated results created at nuclei-final-results.txt"
          echo "Total unique findings: $(wc -l < nuclei-final-results.txt)"

      - name: Upload Final Aggregated Results
        uses: actions/upload-artifact@v4
        with:
          name: final-nuclei-results
          path: nuclei-final-results.txt
          retention-days: 1
